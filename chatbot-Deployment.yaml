kind: Deployment
apiVersion: apps/v1
metadata:
  name: chatbot
  namespace: chatbot
  labels:
    app: chatbot
    app.kubernetes.io/component: chatbot
    app.kubernetes.io/instance: chatbot
spec:
  replicas: 1
  selector:
    matchLabels:
      app: chatbot
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: chatbot
      annotations:
        openshift.io/generated-by: OpenShiftNewApp
    spec:
      containers:
        - resources: {}
          terminationMessagePath: /dev/termination-log
          name: chatbot
          command:
            - /opt/app-root/bin/gunicorn
          env:
            - name: APP_FILE
              value: chatbot.py
            - name: MAX_OUTPUT_TOKENS
              value: '700'
            - name: MODEL_NAME
              value: llama-31-8b-instruct
            - name: STREAM_RESPONSE
              value: 'True'
            - name: TEMPERATURE
              value: '0.7'
            - name: TOP_P
              value: '0.9'
            - name: VLLM_API_BASE_URL
              value: 'https://llama-31-8b-instruct-oai-workshop.apps.cluster-tmgzh.tmgzh.sandbox305.opentlc.com/v1'
          ports:
            - containerPort: 8080
              protocol: TCP
          imagePullPolicy: IfNotPresent
          terminationMessagePolicy: File
          image: amaa1981/chatbot:v4
          args:
            - '--bind'
            - '0.0.0.0:8080'
            - 'chatbot:app'
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      dnsPolicy: ClusterFirst
      securityContext: {}
      schedulerName: default-scheduler
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 25%
      maxSurge: 25%
  revisionHistoryLimit: 10
  progressDeadlineSeconds: 600
