kind: Deployment
apiVersion: apps/v1
metadata:
  annotations:
    deployment.kubernetes.io/revision: '6'
    image.openshift.io/triggers: '[{"from":{"kind":"ImageStreamTag","name":"chatbot:latest"},"fieldPath":"spec.template.spec.containers[?(@.name==\"chatbot\")].image"}]'
  resourceVersion: '507645'
  name: chatbot
  labels:
    app: chatbot
    app.kubernetes.io/component: chatbot
    app.kubernetes.io/instance: chatbot
spec:
  replicas: 1
  selector:
    matchLabels:
      app: chatbot
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: chatbot
    spec:
      containers:
        - resources: {}
          terminationMessagePath: /dev/termination-log
          name: chatbot
          command:
            - /opt/app-root/bin/gunicorn
          env:
            - name: VLLM_API_BASE_URL
              value: 'https://llama-31-8b-instruct-test.apps.cluster-txfv8.txfv8.sandbox265.opentlc.com/v1'
            - name: MODEL_NAME
              value: llama-31-8b-instruct
            - name: TEMPERATURE
              value: '0.7'
            - name: TOP_P
              value: '0.9'
            - name: MAX_OUTPUT_TOKENS
              value: '700'
            - name: STREAM_RESPONSE
              value: 'True'
            - name: APP_FILE
              value: chatbot.py
          ports:
            - containerPort: 8080
              protocol: TCP
          imagePullPolicy: IfNotPresent
          terminationMessagePolicy: File
          image: 'amaa1981/chatbot:v6'
          args:
            - '--bind'
            - '0.0.0.0:8080'
            - 'chatbot:app'
      restartPolicy: Always
      terminationGracePeriodSeconds: 30
      dnsPolicy: ClusterFirst
      securityContext: {}
      schedulerName: default-scheduler
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 25%
      maxSurge: 25%
  revisionHistoryLimit: 10
  progressDeadlineSeconds: 600
